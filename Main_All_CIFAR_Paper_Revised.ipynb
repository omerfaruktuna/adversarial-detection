{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_All_CIFAR_Paper_Revised_Ctesi_16_00.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTbKepqbUv9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b601dd68-094c-4ed3-d032-5fd2cc141316"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: foolbox in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: eagerpy==0.29.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (0.29.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.4.0)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.1.24)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (2.26.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCH3lEpvU2BP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894cb642-2555-4d2c-bef5-3d24b5d1cb60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zItb42WVU37J"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack,L2PGD\n",
        "from time import gmtime, strftime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "import datetime\n",
        "import torch.nn as nn\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import multiprocessing as mp\n",
        "from torch.distributions import Categorical\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HctfhdgU6c9"
      },
      "source": [
        "if not os.path.exists('/content/gdrive/MyDrive/checkpointCIFAR10'):\n",
        "    os.makedirs('/content/gdrive/MyDrive/checkpointCIFAR10')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzcIzIQUVBoC"
      },
      "source": [
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mean = torch.Tensor(mean)\n",
        "        self.std = torch.Tensor(std)\n",
        "    def forward(self, x):\n",
        "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeB0TkkqVag6"
      },
      "source": [
        "class LeNet_dropout(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet_dropout, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(8192, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "        self.drop_layer = nn.Dropout(p=0.50)\n",
        "        self.drop_layer_conv = nn.Dropout2d(p=0.3)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x),inplace=True)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x),inplace=True), kernel_size=2, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv3(x),inplace=True)\n",
        "        x = self.drop_layer_conv(F.max_pool2d(F.relu(self.conv4(x),inplace=True), kernel_size=2, stride=2))\n",
        "\n",
        "        x = F.relu(self.conv5(x),inplace=True)\n",
        "        x = self.drop_layer_conv(F.max_pool2d(F.relu(self.conv6(x),inplace=True), kernel_size=2, stride=2))\n",
        "\n",
        "        x = x.view(-1, 8192)\n",
        "        x = self.drop_layer(F.relu(self.fc1(x)))\n",
        "        x = self.drop_layer(F.relu(self.fc2(x)))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KZrId2yVeYB"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MLP,self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "\n",
        "      nn.Linear(256, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 10),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQDyTYBAWMsm"
      },
      "source": [
        "\n",
        "def train(model, opt, epoch):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    \n",
        "    train_running_correct = 0\n",
        "    train_running_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    lr = opt.param_groups[0]['lr']\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
        "        train_running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        _, preds = torch.max(output.data, 1)\n",
        "        train_running_correct += (preds == target).sum().item()\n",
        "\n",
        "    train_loss = train_running_loss / len(train_loader.dataset)\n",
        "    train_accuracy = 100. * train_running_correct / len(train_loader.dataset)\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}, Epoch: {epoch}, LR: {lr:.5f}')\n",
        "\n",
        "def test(model):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(F.log_softmax(output, dim=1), target, size_average=False).data# sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def mcdropout_test(model):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    enable_dropout(model)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    T = 50\n",
        "\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output_list = []\n",
        "\n",
        "        for i in range(T):\n",
        "            output_list.append(torch.unsqueeze(model(data), 0))\n",
        "\n",
        "        output_mean = torch.cat(output_list, 0).mean(0)\n",
        "        test_loss += F.nll_loss(F.log_softmax(output_mean, dim=1), target, size_average=False).data  # sum up batch loss\n",
        "        pred = output_mean.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nMC Dropout Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "def noise(x, eps, clip_min, clip_max):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    eta = torch.FloatTensor(*x.shape).normal_(mean=0,std=eps)\n",
        "    eta = eta.to(device)\n",
        "    adv_x = x + eta\n",
        "    if clip_min is not None and clip_max is not None:\n",
        "        adv_x = torch.clamp(adv_x, min=clip_min, max=clip_max)\n",
        "    return adv_x\n",
        "\n",
        "def predict_uncertainties(model, image, T=50):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    image = image.to(device)\n",
        "\n",
        "    #torch.manual_seed(2)\n",
        "\n",
        "    image = image.detach()\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    enable_dropout(model)\n",
        "    model.train()\n",
        "\n",
        "    dropout_predictions = torch.zeros([T, item_count, 10])\n",
        "\n",
        "    for t in range(T):\n",
        "\n",
        "        enable_dropout(model)\n",
        "        model.train()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(image)\n",
        "\n",
        "        output_prob = F.softmax(output, dim=1) #shape is 1x10 if item_count is 1 (only one image in input batch)\n",
        "        dropout_predictions[t] = output_prob\n",
        "\n",
        "    #dropout_predictions is of shape 50xitem_countx10\n",
        "\n",
        "    # print(\"dropout predictions shape\", dropout_predictions.shape)\n",
        "\n",
        "    mean = torch.mean(dropout_predictions, dim=0)\n",
        "\n",
        "    entropy = Categorical(probs=mean).entropy()\n",
        "\n",
        "    pred_mean = mean\n",
        "\n",
        "    aleatoric = torch.zeros([item_count,10,10])\n",
        "    epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "    for t in range(T):\n",
        "\n",
        "        pred_t = dropout_predictions[t]\n",
        "\n",
        "        aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "        epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "    aleatoric = aleatoric / T #both of them are of shape item_count x 10x10\n",
        "    epistemic = epistemic / T #both of them are of shape item_count x 10x10\n",
        "\n",
        "    # print(\"aleatoric.shape\", aleatoric.shape)\n",
        "    # print(\"aleatoric.diag.shape\", torch.diagonal(aleatoric, 0, dim1=-2, dim2=-1).shape)\n",
        "\n",
        "    aleatoric = torch.diagonal(aleatoric, 0, dim1=-2, dim2=-1)\n",
        "    epistemic = torch.diagonal(epistemic, 0, dim1=-2, dim2=-1)\n",
        "\n",
        "    aleatoric = torch.mean(aleatoric,1,True)\n",
        "    epistemic = torch.mean(epistemic, 1, True)\n",
        "\n",
        "    scibilic = epistemic / aleatoric\n",
        "\n",
        "    scibilic[torch.isnan(scibilic)] = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return aleatoric.transpose_(0, 1)[0], epistemic.transpose_(0, 1)[0], scibilic.transpose_(0, 1)[0], entropy\n",
        "\n",
        "def calculate_distance(model, predictions, last_hidden_layer_outs):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total = []\n",
        "\n",
        "    for z in range(last_hidden_layer_outs.shape[0]):\n",
        "\n",
        "        hidden_tensor = torch.from_numpy(last_hidden_layer_outs[z])\n",
        "\n",
        "        hidden_tensor = hidden_tensor.to(device)\n",
        "\n",
        "        hidden_tensor = torch.unsqueeze(hidden_tensor, 0)\n",
        "\n",
        "        total.append(F.softmax(model(hidden_tensor) / 1, dim=1)[0][predictions[z].item()])\n",
        "\n",
        "    return torch.Tensor(total)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLk3qfwjXTER"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "learning_rate = 0.001\n",
        "epoch = 75\n",
        "\n",
        "model_dropout = LeNet_dropout()\n",
        "model_dropout = model_dropout.to(device)\n",
        "\n",
        "optimizer_dropout = optim.Adam(model_dropout.parameters(), lr=learning_rate)\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 2 every 15 epochs\"\"\"\n",
        "    lr = learning_rate * (0.5 ** (epoch // 15))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poL7mwGRWR8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7448e4-bacb-4614-9efc-7d2ddffe1dff"
      },
      "source": [
        "\n",
        "print(\"Press 0, 1, 2 , 3 , 4 , 5 :\\ntrain mode (0)\\ntest set uncertainty metrics for correct and wrong predictions (1)\\nPrepare Last Hidden Layer Outputs (2)\\nTrain MLP (3)\\nPrepare Data (4)\\nPlot Performances (5)\\n\")\n",
        "\n",
        "input_a = int(input())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Press 0, 1, 2 , 3 , 4 , 5 :\n",
            "train mode (0)\n",
            "test set uncertainty metrics for correct and wrong predictions (1)\n",
            "Prepare Last Hidden Layer Outputs (2)\n",
            "Train MLP (3)\n",
            "Prepare Data (4)\n",
            "Plot Performances (5)\n",
            "\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NltwGLsJWVII"
      },
      "source": [
        "if input_a == 0:\n",
        "    \n",
        "    train_data = datasets.CIFAR10(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=256, shuffle=False)\n",
        "\n",
        "    print ('Train Lenet with dropout at all layer')\n",
        "    for epoch in range(1, epoch + 1):\n",
        "        adjust_learning_rate(optimizer_dropout, epoch)\n",
        "        train(model_dropout, optimizer_dropout, epoch)\n",
        "        test(model_dropout)\n",
        "\n",
        "    print(\"Test Set results of dropout model\")\n",
        "    test(model_dropout)\n",
        "    #print(\"MC Dropout Test Results of dropout model\")\n",
        "    #mcdropout_test(model_dropout)\n",
        "\n",
        "    print('Save /content/gdrive/MyDrive/checkpointCIFAR10/' + 'LeNet_dropout' + '.pth.tar')\n",
        "    state = {'state_dict': model_dropout.state_dict()}\n",
        "    filename = '/content/gdrive/MyDrive/checkpointCIFAR10/' + 'LeNet_dropout' + '.pth.tar'\n",
        "    torch.save(state, filename)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5msR8dxWjTj"
      },
      "source": [
        "if input_a == 1:\n",
        "\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_dropout.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    model_dropout.eval()\n",
        "    model_dropout = model_dropout.to(device)\n",
        "\n",
        "    print(\"Beginning time is : \")\n",
        "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "    first_time = datetime.datetime.now()\n",
        "\n",
        "    al_clean_tensor_corrects = torch.empty(0)\n",
        "    ep_clean_tensor_corrects = torch.empty(0)\n",
        "    sc_clean_tensor_corrects = torch.empty(0)\n",
        "    ent_clean_tensor_corrects = torch.empty(0)\n",
        "\n",
        "    al_clean_tensor_wrongs = torch.empty(0)\n",
        "    ep_clean_tensor_wrongs = torch.empty(0)\n",
        "    sc_clean_tensor_wrongs = torch.empty(0)\n",
        "    ent_clean_tensor_wrongs = torch.empty(0)\n",
        "\n",
        "    a = 0\n",
        "\n",
        "    for test_images, test_labels in test_loader:\n",
        "\n",
        "        test_images = test_images.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "\n",
        "        model_dropout.eval()\n",
        "        sample_image = test_images\n",
        "        sample_label = test_labels\n",
        "        outputs = model_dropout(test_images)\n",
        "        corrects = (outputs.max(dim=1)[1] == test_labels)\n",
        "        wrongs = (outputs.max(dim=1)[1] != test_labels)\n",
        "\n",
        "        sample_image_corrects = sample_image[corrects]\n",
        "        sample_label_corrects = sample_label[corrects]\n",
        "\n",
        "        sample_image_wrongs = sample_image[wrongs]\n",
        "        sample_label_wrongs = sample_label[wrongs]\n",
        "\n",
        "\n",
        "        al_clean_corrects, ep_clean_corrects, sc_clean_corrects, ent_clean_corrects = predict_uncertainties(model_dropout, sample_image_corrects, 50)\n",
        "\n",
        "        al_clean_tensor_corrects = torch.cat([al_clean_tensor_corrects, al_clean_corrects])\n",
        "        ep_clean_tensor_corrects = torch.cat([ep_clean_tensor_corrects, ep_clean_corrects])\n",
        "        sc_clean_tensor_corrects = torch.cat([sc_clean_tensor_corrects, sc_clean_corrects])\n",
        "        ent_clean_tensor_corrects = torch.cat([ent_clean_tensor_corrects, ent_clean_corrects])\n",
        "\n",
        "        if sample_image_wrongs.shape[0] != 0:\n",
        "\n",
        "            al_clean_wrongs, ep_clean_wrongs, sc_clean_wrongs, ent_clean_wrongs = predict_uncertainties(model_dropout, sample_image_wrongs, 50)\n",
        "\n",
        "            al_clean_tensor_wrongs = torch.cat([al_clean_tensor_wrongs, al_clean_wrongs])\n",
        "            ep_clean_tensor_wrongs = torch.cat([ep_clean_tensor_wrongs, ep_clean_wrongs])\n",
        "            sc_clean_tensor_wrongs = torch.cat([sc_clean_tensor_wrongs, sc_clean_wrongs])\n",
        "            ent_clean_tensor_wrongs = torch.cat([ent_clean_tensor_wrongs, ent_clean_wrongs])\n",
        "\n",
        "    print(\"PREPARING CLEAN DATA FOR CORRECTS....\")\n",
        "    al_clean_tensor_corrects, ep_clean_tensor_corrects, sc_clean_tensor_corrects, ent_clean_tensor_corrects = al_clean_tensor_corrects.numpy(), ep_clean_tensor_corrects.numpy(), sc_clean_tensor_corrects.numpy(), ent_clean_tensor_corrects.numpy()\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"PREPARING CLEAN DATA FOR WRONGS...\")\n",
        "    al_clean_tensor_wrongs, ep_clean_tensor_wrongs, sc_clean_tensor_wrongs, ent_clean_tensor_wrongs = al_clean_tensor_wrongs.numpy(), ep_clean_tensor_wrongs.numpy(), sc_clean_tensor_wrongs.numpy(), ent_clean_tensor_wrongs.numpy()\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"\\nMean of the aleatoric uncertainty values for all the errors : \", al_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the aleatoric uncertainty values for all the corrects \", al_clean_tensor_corrects.mean())\n",
        "\n",
        "    print(\"\\nMean of the epistemic uncertainty values for all the errors : \", ep_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the epistemic uncertainty values for all the corrects \", ep_clean_tensor_corrects.mean())\n",
        "\n",
        "    print(\"\\nMean of the scibilic uncertainty values for all the errors : \", sc_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the scibilic uncertainty values for all the corrects \", sc_clean_tensor_corrects.mean())\n",
        "\n",
        "    print(\"\\nMean of the entropy values for all the errors : \", ent_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the entropy values for all the corrects \", ent_clean_tensor_corrects.mean())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hciP2_3YXmFk"
      },
      "source": [
        "if input_a == 2:\n",
        "\n",
        "    train_data = datasets.CIFAR10(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=64, shuffle=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    norm = Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "    preprocessing = dict(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261], axis=-3)\n",
        "\n",
        "    model_attack = LeNet_dropout()\n",
        "    ckpt_attack = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_attack.load_state_dict(ckpt_attack['state_dict'])\n",
        "    model_attack.eval()\n",
        "    model_attack = model_attack.to(device)\n",
        "\n",
        "    last_hidden_idx = -4\n",
        "    output_dim = list(model_attack.children())[last_hidden_idx].out_features\n",
        "    print(output_dim)\n",
        "\n",
        "    ################ CLEAN LAST HIDDEN LAYER OUTPUTS ####################\n",
        "    last_hidden_layer_outputs = np.empty((0, output_dim))\n",
        "    predss = np.empty((0))\n",
        "    labelss = np.empty((0))\n",
        "\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model_attack(image)\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        pred = pred.view_as(label)\n",
        "        predss = np.hstack((predss, pred.detach().cpu().numpy()))\n",
        "        labelss = np.hstack((labelss, label.cpu().numpy()))\n",
        "\n",
        "        last_hidden_layer_outputs = np.vstack(\n",
        "            (last_hidden_layer_outputs, model_attack.last_hidden_layer_output(image).detach().cpu().numpy()))\n",
        "\n",
        "    inds_correct = np.where(predss == labelss)[0]\n",
        "\n",
        "    predss = predss[inds_correct]\n",
        "    labelss = labelss[inds_correct]\n",
        "    last_hidden_layer_outputs = last_hidden_layer_outputs[inds_correct]\n",
        "\n",
        "    ################ ADVERSARIAL LAST HIDDEN LAYER OUTPUTS ####################\n",
        "\n",
        "    adv_last_hidden_layer_outputs = np.empty((0, output_dim))\n",
        "\n",
        "    model_attack.eval()\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        attack = LinfBasicIterativeAttack()\n",
        "        fmodel = PyTorchModel(model_attack, bounds=(0, 1))\n",
        "        raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[0.03])\n",
        "        pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            adv_last_hidden_layer_outputs = np.vstack(\n",
        "                (adv_last_hidden_layer_outputs, model_attack.last_hidden_layer_output(pert).cpu().numpy()))\n",
        "\n",
        "    adv_last_hidden_layer_outputs = adv_last_hidden_layer_outputs[inds_correct]\n",
        "\n",
        "    ################ NOSIY LAST HIDDEN LAYER OUTPUTS ####################\n",
        "\n",
        "    noisy_last_hidden_layer_outputs = np.empty((0, output_dim))\n",
        "\n",
        "    model_attack.eval()\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        noisy_image = noise(image, 0.03, 0, 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            noisy_last_hidden_layer_outputs = np.vstack(\n",
        "                (noisy_last_hidden_layer_outputs, model_attack.last_hidden_layer_output(noisy_image).cpu().numpy()))\n",
        "\n",
        "    noisy_last_hidden_layer_outputs = noisy_last_hidden_layer_outputs[inds_correct]\n",
        "\n",
        "    ###############\n",
        "\n",
        "    dig_outputs = {}\n",
        "    dig_outputs_raw = {}\n",
        "    dig_labels = {}\n",
        "    dig_labels_raw = {}\n",
        "    dig_outputs_adv = {}\n",
        "    dig_outputs_adv_raw = {}\n",
        "    dig_outputs_noisy = {}\n",
        "    dig_outputs_noisy_raw = {}\n",
        "\n",
        "    for i in range(10):\n",
        "        inds_i = np.where(predss == i)[0]\n",
        "\n",
        "        dig_outputs_raw[i] = last_hidden_layer_outputs[inds_i]\n",
        "        dummy = dig_outputs_raw[i].copy()\n",
        "\n",
        "        dig_labels_raw[i] = labelss[inds_i]\n",
        "        dummy_labels = dig_labels_raw[i].copy()\n",
        "\n",
        "        dig_outputs_adv_raw[i] = adv_last_hidden_layer_outputs[inds_i]\n",
        "        dummy_adv = dig_outputs_adv_raw[i].copy()\n",
        "\n",
        "        dig_outputs_noisy_raw[i] = noisy_last_hidden_layer_outputs[inds_i]\n",
        "        dummy_noisy = dig_outputs_noisy_raw[i].copy()\n",
        "\n",
        "        rows = dummy.shape[0]\n",
        "\n",
        "        dig_outputs[i] = dummy\n",
        "        dig_labels[i] = dummy_labels\n",
        "        dig_outputs_adv[i] = dummy_adv\n",
        "        dig_outputs_noisy[i] = dummy_noisy\n",
        "\n",
        "    for i in range(10):\n",
        "        filename = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_' + str(i) + '.npy'\n",
        "        np.save(filename, dig_outputs[i])\n",
        "\n",
        "        filename2 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_labels_' + str(i) + '.npy'\n",
        "        np.save(filename2, dig_labels[i])\n",
        "\n",
        "        filename3 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_adv_' + str(i) + '.npy'\n",
        "        np.save(filename3, dig_outputs_adv[i])\n",
        "\n",
        "        filename4 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_noisy' + str(i) + '.npy'\n",
        "        np.save(filename4, dig_outputs_noisy[i])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqw6NJdZ3AA"
      },
      "source": [
        "if input_a == 3:\n",
        "\n",
        "    my_mlp_model = MLP()\n",
        "    my_mlp_model = my_mlp_model.to(device)\n",
        "\n",
        "    model_attack_new = LeNet_dropout()\n",
        "    ckpt_attack_new = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_attack_new.load_state_dict(ckpt_attack_new['state_dict'])\n",
        "    model_attack_new.eval()\n",
        "    model_attack_new = model_attack_new.to(device)\n",
        "\n",
        "    dig_labels = {}\n",
        "    dig_outputs = {}\n",
        "    dig_outputs_adv = {}\n",
        "    dig_outputs_noisy = {}\n",
        "\n",
        "    data = np.empty((0, 256))\n",
        "    labels = np.empty((0, 1))\n",
        "\n",
        "    for i in range(10):\n",
        "        filename = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_' + str(i) + '.npy'\n",
        "        dig_outputs[i] = np.load(filename)\n",
        "\n",
        "        filename3 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_adv_' + str(i) + '.npy'\n",
        "        dig_outputs_adv[i] = np.load(filename3)\n",
        "\n",
        "        filename4 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_noisy' + str(i) + '.npy'\n",
        "        dig_outputs_noisy[i] = np.load(filename4)\n",
        "\n",
        "        filename2 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_labels_' + str(i) + '.npy'\n",
        "        dig_labels[i] = np.load(filename2)\n",
        "\n",
        "        dig_labels[i] = np.expand_dims(dig_labels[i], axis=1)\n",
        "\n",
        "        data = np.vstack((data, dig_outputs[i]))\n",
        "        data = np.vstack((data, dig_outputs_adv[i]))\n",
        "        data = np.vstack((data, dig_outputs_noisy[i]))\n",
        "        labels = np.vstack((labels, dig_labels[i]))\n",
        "        labels = np.vstack((labels, dig_labels[i]))\n",
        "        labels = np.vstack((labels, dig_labels[i]))\n",
        "\n",
        "    labels = np.squeeze(labels, axis=1)\n",
        "\n",
        "    print(\"labels shape \", labels.shape)\n",
        "    print(\"data shape \", data.shape)\n",
        "\n",
        "    train_data = []\n",
        "    for i in range(len(data)):\n",
        "        train_data.append([data[i], labels[i]])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=128)\n",
        "\n",
        "    my_mlp_model.train()\n",
        "\n",
        "    lr = 0.001\n",
        "    opt = optim.Adam(my_mlp_model.parameters(), lr=lr)\n",
        "    T = 1\n",
        "\n",
        "    my_mlp_model.train()\n",
        "\n",
        "    for epoch in range(180):\n",
        "\n",
        "        total_err = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            data = data.float()\n",
        "            target = target.long()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            output = my_mlp_model(data)\n",
        "            loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_err += (output.max(dim=1)[1] != target).sum().item()\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)] lr: {}\\tLoss: {:.6f}'\n",
        "                      .format(epoch, batch_idx * len(data),\n",
        "                              len(train_loader.dataset),\n",
        "                              100. * batch_idx / len(train_loader),\n",
        "                              lr, loss.data))\n",
        "        print('*******Train Epoch: {} error is {}'.format(epoch + 1, total_err))\n",
        "\n",
        "    my_mlp_model.eval()\n",
        "    print('Save /content/gdrive/MyDrive/checkpointCIFAR10/' + 'MLP_Modell' + '.pth.tar')\n",
        "    state = {'state_dict': my_mlp_model.state_dict()}\n",
        "    filename = '/content/gdrive/MyDrive/checkpointCIFAR10/' + 'MLP_Modell' + '.pth.tar'\n",
        "    torch.save(state, filename)\n",
        "\n",
        "    my_mlp_model_2 = MLP()\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/MLP_Modell.pth.tar')\n",
        "    my_mlp_model_2.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    my_mlp_model_2.eval()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMoZiuzalHw"
      },
      "source": [
        "if input_a == 4:\n",
        "\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_dropout.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    model_dropout.eval()\n",
        "    model_dropout = model_dropout.to(device)\n",
        "\n",
        "    my_mlp_model_2 = MLP()\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/MLP_Modell.pth.tar')\n",
        "    my_mlp_model_2.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    my_mlp_model_2.eval()\n",
        "    my_mlp_model_2 = my_mlp_model_2.to(device)\n",
        "\n",
        "\n",
        "    print(\"Chose attack type: \\nDeepfool (1)\\nFGSM  (2)\\nBIM  (3)\\nCW  (4)\\nPGD  (5)\\n\")\n",
        "\n",
        "    input_c = int(input())\n",
        "\n",
        "    print(\"Enter epsilon value : \\n\")\n",
        "\n",
        "    eps = float(input())\n",
        "    eps_str = str(int((eps + 0.0000001) * 100))\n",
        "\n",
        "    if input_c == 1:\n",
        "        attack = LinfDeepFoolAttack()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"Deepfool\"\n",
        "        eps_noisy = eps\n",
        "    elif input_c == 2:\n",
        "        attack = LinfFastGradientAttack()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"FGSM\"\n",
        "        eps_noisy = eps\n",
        "    elif input_c == 3:\n",
        "        attack = LinfBasicIterativeAttack()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"BIM\"\n",
        "        eps_noisy = eps\n",
        "    elif input_c == 4:\n",
        "\n",
        "        if eps == 0.02:\n",
        "            eps = 0.532 #############################################################\n",
        "            eps_noisy = 0.02\n",
        "        if eps == 0.03:\n",
        "            eps = 0.798 #############################################################\n",
        "            eps_noisy = 0.03 \n",
        "        if eps == 0.04:\n",
        "            eps = 1.064 #############################################################\n",
        "            eps_noisy = 0.04 \n",
        "        print(eps)\n",
        "        attack = L2CarliniWagnerAttack(steps=1000)\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"CW\"\n",
        "    elif input_c == 5:\n",
        "        attack = LinfPGD()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"PGD\"\n",
        "        eps_noisy = eps\n",
        "\n",
        "    print(\"Chosen attack type is \", attack_type)\n",
        "    print(\"Chosen epsilon is \", eps)\n",
        "\n",
        "    print(\"Prepared data will be stored at: \")\n",
        "    print(f\"/content/gdrive/MyDrive/checkpointCIFAR10/all_numpy_{attack_type}_0{eps_str}.npy\")\n",
        "\n",
        "    print(\"Beginning time is : \")\n",
        "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "    first_time = datetime.datetime.now()\n",
        "\n",
        "    al_clean_tensor = torch.empty(0)\n",
        "    ep_clean_tensor = torch.empty(0)\n",
        "    sc_clean_tensor = torch.empty(0)\n",
        "    ent_clean_tensor = torch.empty(0)\n",
        "    preds_clean_tensor = torch.empty(0)\n",
        "    distances_clean_tensor = torch.empty(0)\n",
        "\n",
        "    al_noisy_tensor = torch.empty(0)\n",
        "    ep_noisy_tensor = torch.empty(0)\n",
        "    sc_noisy_tensor = torch.empty(0)\n",
        "    ent_noisy_tensor = torch.empty(0)\n",
        "    preds_noisy_tensor = torch.empty(0)\n",
        "    distances_noisy_tensor = torch.empty(0)\n",
        "\n",
        "    al_dirty_tensor = torch.empty(0)\n",
        "    ep_dirty_tensor = torch.empty(0)\n",
        "    sc_dirty_tensor = torch.empty(0)\n",
        "    ent_dirty_tensor = torch.empty(0)\n",
        "    preds_dirty_tensor = torch.empty(0)\n",
        "    distances_dirty_tensor = torch.empty(0)\n",
        "\n",
        "    preds_clean_tensor = preds_clean_tensor.to(device)\n",
        "    preds_noisy_tensor = preds_noisy_tensor.to(device)\n",
        "    preds_dirty_tensor = preds_dirty_tensor.to(device)\n",
        "\n",
        "\n",
        "    for test_images, test_labels in test_loader:\n",
        "\n",
        "        test_images = test_images.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "\n",
        "        model_dropout.eval()\n",
        "        sample_image = test_images\n",
        "        sample_label = test_labels\n",
        "        outputs = model_dropout(test_images)\n",
        "        preds = outputs.max(dim=1)[1]\n",
        "        corrects = (preds == test_labels)\n",
        "        sample_image = sample_image[corrects]\n",
        "        sample_label = sample_label[corrects]\n",
        "        preds = preds[corrects]\n",
        "        preds = preds.to(device)\n",
        "\n",
        "        al_clean, ep_clean, sc_clean, ent_clean = predict_uncertainties(model_dropout, sample_image, 50)\n",
        "\n",
        "\n",
        "        al_clean_tensor = torch.cat([al_clean_tensor, al_clean])\n",
        "        ep_clean_tensor = torch.cat([ep_clean_tensor, ep_clean])\n",
        "        sc_clean_tensor = torch.cat([sc_clean_tensor, sc_clean])\n",
        "        ent_clean_tensor = torch.cat([ent_clean_tensor, ent_clean])\n",
        "        preds_clean_tensor = torch.cat([preds_clean_tensor, preds])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        with torch.no_grad():\n",
        "            last_hidden_layer_outputs_clean = model_dropout.last_hidden_layer_output(sample_image).detach().cpu().numpy()\n",
        "\n",
        "        distances_clean = calculate_distance(my_mlp_model_2, preds, last_hidden_layer_outputs_clean)\n",
        "\n",
        "        distances_clean_tensor = torch.cat([distances_clean_tensor, distances_clean])\n",
        "\n",
        "#########################\n",
        "\n",
        "        image_noisy = noise(sample_image, eps_noisy, 0, 1)\n",
        "\n",
        "        al_noisy, ep_noisy, sc_noisy, ent_noisy = predict_uncertainties(model_dropout, image_noisy, 50)\n",
        "\n",
        "        al_noisy_tensor = torch.cat([al_noisy_tensor, al_noisy])\n",
        "        ep_noisy_tensor = torch.cat([ep_noisy_tensor, ep_noisy])\n",
        "        sc_noisy_tensor = torch.cat([sc_noisy_tensor, sc_noisy])\n",
        "        ent_noisy_tensor = torch.cat([ent_noisy_tensor, ent_noisy])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        outputs_noisy = model_dropout(image_noisy)\n",
        "        preds_noisy = outputs_noisy.max(dim=1)[1]\n",
        "\n",
        "        preds_noisy_tensor = torch.cat([preds_noisy_tensor, preds_noisy])\n",
        "\n",
        "\n",
        "        model_dropout.eval()\n",
        "        with torch.no_grad():\n",
        "            last_hidden_layer_outputs_noisy = model_dropout.last_hidden_layer_output(image_noisy).detach().cpu().numpy()\n",
        "\n",
        "        distances_noisy = calculate_distance(my_mlp_model_2, preds_noisy, last_hidden_layer_outputs_noisy)\n",
        "\n",
        "        distances_noisy_tensor = torch.cat([distances_noisy_tensor, distances_noisy])\n",
        "\n",
        "#########################\n",
        "\n",
        "        raw_advs, clipped_advs, success = attack(fmodel, sample_image, sample_label, epsilons=[eps])\n",
        "        image_dirty = torch.tensor(clipped_advs[0])\n",
        "\n",
        "        al_dirty, ep_dirty, sc_dirty, ent_dirty = predict_uncertainties(model_dropout, image_dirty, 50)\n",
        "\n",
        "        al_dirty_tensor = torch.cat([al_dirty_tensor, al_dirty])\n",
        "        ep_dirty_tensor = torch.cat([ep_dirty_tensor, ep_dirty])\n",
        "        sc_dirty_tensor = torch.cat([sc_dirty_tensor, sc_dirty])\n",
        "        ent_dirty_tensor = torch.cat([ent_dirty_tensor, ent_dirty])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        outputs_dirty = model_dropout(image_dirty)\n",
        "        preds_dirty = outputs_dirty.max(dim=1)[1]\n",
        "\n",
        "        preds_dirty_tensor = torch.cat([preds_dirty_tensor, preds_dirty])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        with torch.no_grad():\n",
        "            last_hidden_layer_outputs_dirty = model_dropout.last_hidden_layer_output(image_dirty).detach().cpu().numpy()\n",
        "\n",
        "        distances_dirty = calculate_distance(my_mlp_model_2, preds_dirty, last_hidden_layer_outputs_dirty)\n",
        "\n",
        "        distances_dirty_tensor = torch.cat([distances_dirty_tensor, distances_dirty])\n",
        "\n",
        "    #########################\n",
        "\n",
        "    print(\"PREPARING CLEAN DATA....\")\n",
        "\n",
        "    al_clean_tensor, ep_clean_tensor, sc_clean_tensor, ent_clean_tensor = al_clean_tensor.cpu().numpy(), ep_clean_tensor.cpu().numpy(), sc_clean_tensor.cpu().numpy(), ent_clean_tensor.cpu().numpy()\n",
        "    \n",
        "    zero_clean_tensor = np.zeros_like(al_clean_tensor)\n",
        "\n",
        "    distances_clean_tensor = distances_clean_tensor.cpu().numpy()\n",
        "\n",
        "    preds_clean_tensor = preds_clean_tensor.cpu().numpy()\n",
        "\n",
        "    al_clean_tensor = al_clean_tensor.reshape(al_clean_tensor.shape[0], 1)\n",
        "    ep_clean_tensor = ep_clean_tensor.reshape(ep_clean_tensor.shape[0], 1)\n",
        "    sc_clean_tensor = sc_clean_tensor.reshape(sc_clean_tensor.shape[0], 1)\n",
        "    ent_clean_tensor = ent_clean_tensor.reshape(ent_clean_tensor.shape[0], 1)\n",
        "    zero_clean_tensor = zero_clean_tensor.reshape(zero_clean_tensor.shape[0], 1)\n",
        "    preds_clean_tensor = preds_clean_tensor.reshape(preds_clean_tensor.shape[0], 1)\n",
        "    distances_clean_tensor = distances_clean_tensor.reshape(distances_clean_tensor.shape[0],1)\n",
        "\n",
        "    clean_tensor_all = np.concatenate((al_clean_tensor,ep_clean_tensor,sc_clean_tensor,ent_clean_tensor,preds_clean_tensor,distances_clean_tensor,zero_clean_tensor),axis=1)\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"PREPARING NOISY DATA....\")\n",
        "\n",
        "    al_noisy_tensor, ep_noisy_tensor, sc_noisy_tensor, ent_noisy_tensor = al_noisy_tensor.cpu().numpy(), ep_noisy_tensor.cpu().numpy(), sc_noisy_tensor.cpu().numpy(), ent_noisy_tensor.cpu().numpy()\n",
        "\n",
        "    zero_noisy_tensor = np.zeros_like(al_noisy_tensor)\n",
        "\n",
        "    distances_noisy_tensor = distances_noisy_tensor.cpu().numpy()\n",
        "\n",
        "    preds_noisy_tensor = preds_noisy_tensor.cpu().numpy()\n",
        "\n",
        "    al_noisy_tensor = al_noisy_tensor.reshape(al_noisy_tensor.shape[0], 1)\n",
        "    ep_noisy_tensor = ep_noisy_tensor.reshape(ep_noisy_tensor.shape[0], 1)\n",
        "    sc_noisy_tensor = sc_noisy_tensor.reshape(sc_noisy_tensor.shape[0], 1)\n",
        "    ent_noisy_tensor = ent_noisy_tensor.reshape(ent_noisy_tensor.shape[0], 1)\n",
        "    zero_noisy_tensor = zero_noisy_tensor.reshape(zero_noisy_tensor.shape[0], 1)\n",
        "    preds_noisy_tensor = preds_noisy_tensor.reshape(preds_noisy_tensor.shape[0], 1)\n",
        "    distances_noisy_tensor = distances_noisy_tensor.reshape(distances_noisy_tensor.shape[0],1)\n",
        "\n",
        "\n",
        "    noisy_tensor_all = np.concatenate((al_noisy_tensor,ep_noisy_tensor,sc_noisy_tensor,ent_noisy_tensor,preds_noisy_tensor,distances_noisy_tensor,zero_noisy_tensor),axis=1)\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"PREPARING DIRTY DATA....\")\n",
        "\n",
        "    al_dirty_tensor, ep_dirty_tensor, sc_dirty_tensor, ent_dirty_tensor = al_dirty_tensor.cpu().numpy(), ep_dirty_tensor.cpu().numpy(), sc_dirty_tensor.cpu().numpy(), ent_dirty_tensor.cpu().numpy()\n",
        "\n",
        "    ones_dirty_tensor = np.ones_like(ep_dirty_tensor)\n",
        "\n",
        "    distances_dirty_tensor = distances_dirty_tensor.cpu().numpy()\n",
        "\n",
        "    preds_dirty_tensor = preds_dirty_tensor.cpu().numpy()\n",
        "\n",
        "    al_dirty_tensor = al_dirty_tensor.reshape(al_dirty_tensor.shape[0], 1)\n",
        "    ep_dirty_tensor = ep_dirty_tensor.reshape(ep_dirty_tensor.shape[0], 1)\n",
        "    sc_dirty_tensor = sc_dirty_tensor.reshape(sc_dirty_tensor.shape[0], 1)\n",
        "    ent_dirty_tensor = ent_dirty_tensor.reshape(ent_dirty_tensor.shape[0], 1)\n",
        "    ones_dirty_tensor = ones_dirty_tensor.reshape(ones_dirty_tensor.shape[0], 1)\n",
        "    preds_dirty_tensor = preds_dirty_tensor.reshape(preds_dirty_tensor.shape[0], 1)\n",
        "    distances_dirty_tensor = distances_dirty_tensor.reshape(distances_dirty_tensor.shape[0],1)\n",
        "\n",
        "\n",
        "    dirty_tensor_all = np.concatenate((al_dirty_tensor,ep_dirty_tensor,sc_dirty_tensor,ent_dirty_tensor,preds_dirty_tensor,distances_dirty_tensor,ones_dirty_tensor),axis=1)\n",
        "\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print(\"epistemic uncertainty clean shape \", ep_clean_tensor.shape)\n",
        "    print(\"distance tensor clean shape \", distances_clean_tensor.shape)\n",
        "    print(\"distance tensor noisy shape \", distances_noisy_tensor.shape)\n",
        "    print(\"distance tensor dirty shape \", distances_dirty_tensor.shape)\n",
        "    print(\"preds tensor dirty shape \", preds_dirty_tensor.shape)\n",
        "    print(\"clean data all shape \", clean_tensor_all.shape)\n",
        "    print(\"noisy data all shape \", noisy_tensor_all.shape)\n",
        "    print(\"dirty data all shape \", dirty_tensor_all.shape)\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    all_tensor_all = np.concatenate((clean_tensor_all,noisy_tensor_all,dirty_tensor_all),axis=0)\n",
        "\n",
        "    print(\"shape of all data is: \")\n",
        "    print(all_tensor_all.shape)\n",
        "    print()\n",
        "\n",
        "    np.save(f\"/content/gdrive/MyDrive/checkpointCIFAR10/all_numpy_{attack_type}_0{eps_str}.npy\", all_tensor_all)\n",
        "\n",
        "    print(\"For Clean data\")\n",
        "    print(\"Number of features : \", al_clean_tensor.shape[0])\n",
        "\n",
        "    print(\"aleatoric :\", al_clean_tensor.mean())\n",
        "    print(\"epistemic :\", ep_clean_tensor.mean())\n",
        "    print(\"scibilic :\", sc_clean_tensor.mean())\n",
        "    print(\"entropy :\", ent_clean_tensor.mean())\n",
        "    print(\"distance :\", distances_clean_tensor.mean())\n",
        "\n",
        "    print(\"For Noisy data\")\n",
        "    print(\"Number of features : \", al_noisy_tensor.shape[0])\n",
        "\n",
        "\n",
        "    print(\"aleatoric :\", al_noisy_tensor.mean())\n",
        "    print(\"epistemic :\", ep_noisy_tensor.mean())\n",
        "    print(\"scibilic :\", sc_noisy_tensor.mean())\n",
        "    print(\"entropy :\", ent_noisy_tensor.mean())\n",
        "    print(\"distance :\", distances_noisy_tensor.mean())\n",
        "\n",
        "    print(\"For Dirty data\")\n",
        "    print(\"Number of features : \", al_dirty_tensor.shape[0])\n",
        "\n",
        "\n",
        "    print(\"aleatoric :\", al_dirty_tensor.mean())\n",
        "    print(\"epistemic :\", ep_dirty_tensor.mean())\n",
        "    print(\"scibilic :\", sc_dirty_tensor.mean())\n",
        "    print(\"entropy :\", ent_dirty_tensor.mean())\n",
        "    print(\"distance :\", distances_dirty_tensor.mean())\n",
        "    print()\n",
        "\n",
        "    print(\"End time is : \")\n",
        "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "    print()\n",
        "\n",
        "    later_time = datetime.datetime.now()\n",
        "    difference = later_time - first_time\n",
        "    seconds_in_day = 24 * 60 * 60\n",
        "    print(\"Duration in minutes and seconds is : \")\n",
        "    print(divmod(difference.days * seconds_in_day + difference.seconds, 60))\n",
        "\n",
        "    print(\"####################################\")\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqJXpAVjcBRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "2a9637de-74b0-4b26-ce22-3a45906ca6ec"
      },
      "source": [
        "if input_a == 5:\n",
        "\n",
        "    #test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "    #test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "    \n",
        "    #ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    #model_dropout.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    #model_dropout.eval()\n",
        "    #model_dropout = model_dropout.to(device)\n",
        "\n",
        "    #test(model_dropout)\n",
        "\n",
        "    print(\"Chose data attack type: \\nDeepfool (1)\\nFGSM  (2)\\nBIM  (3)\\nCW  (4)\\nPGD  (5)\\n\")\n",
        "\n",
        "    input_c = int(input())\n",
        "\n",
        "    if input_c == 1:\n",
        "        attack_type = \"Deepfool\"\n",
        "    elif input_c == 2:\n",
        "        attack_type = \"FGSM\"\n",
        "    elif input_c == 3:\n",
        "        attack_type = \"BIM\"\n",
        "    elif input_c == 4:\n",
        "        attack_type = \"CW\"\n",
        "    elif input_c == 5:\n",
        "        attack_type = \"PGD\"\n",
        "\n",
        "    directory = '/content/gdrive/MyDrive/checkpointCIFAR10/' + attack_type\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    print(\"Enter epsilon value : \\n\")\n",
        "\n",
        "    eps = float(input())\n",
        "    eps_str = str(int((eps+0.0000001)*100))\n",
        "\n",
        "    print(\"Chosen attack type is \", attack_type)\n",
        "    print(\"Chosen epsilon is \", eps)\n",
        "\n",
        "    train_data = f\"/content/gdrive/MyDrive/checkpointCIFAR10/all_numpy_{attack_type}_0{eps_str}.npy\"\n",
        "    tail = f\"_{attack_type}_0{eps_str}.npy\"\n",
        "\n",
        "\n",
        "    train_data_all_numpy = np.load(train_data)\n",
        "    train_data_all_numpy_shuffled = shuffle(train_data_all_numpy, random_state=0)\n",
        "\n",
        "    cols = [[0], [1], [2], [3], [5], [0, 1, 2, 3, 5]]\n",
        "\n",
        "    fpr_list = [\"fpr_aleatoric\", \"fpr_epistemic\", \"fpr_scibilic\", \"fpr_entropy\", \"fpr_distance\", \"fpr_All\"]\n",
        "\n",
        "    tpr_list = [\"tpr_aleatoric\", \"tpr_epistemic\", \"tpr_scibilic\", \"tpr_entropy\", \"fpr_distance\", \"tpr_All\"]\n",
        "\n",
        "    roc_auc_list = [\"roc_auc_aleatoric\", \"roc_auc_epistemic\", \"roc_auc_scibilic\", \"roc_auc_entropy\", \"roc_auc_distance\", \"roc_auc_All\"]\n",
        "\n",
        "    legend_label = ['Aleatoric', 'Epistemic', 'Scibilic', 'Entropy', 'Distance', 'All']\n",
        "\n",
        "    for i,c in enumerate(cols):\n",
        "\n",
        "        col_idx = np.array(c)\n",
        "\n",
        "        X_train = train_data_all_numpy_shuffled[:, col_idx]\n",
        "        y_train = train_data_all_numpy_shuffled[:, -1]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "\n",
        "        logisticRegr = LogisticRegressionCV()\n",
        "        lr = logisticRegr.fit(X_train, y_train)\n",
        "\n",
        "        probs = lr.predict_proba(X_train)\n",
        "        preds = probs[:, 1]\n",
        "\n",
        "        fpr, tpr, threshold = metrics.roc_curve(y_train, preds)\n",
        "\n",
        "        roc_auc = []\n",
        "        roc_auc.append(metrics.auc(fpr, tpr))\n",
        "\n",
        "        fpr = np.array(fpr)\n",
        "        np.save(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + fpr_list[i] + tail, fpr)\n",
        "\n",
        "        tpr = np.array(tpr)\n",
        "        np.save(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + tpr_list[i] + tail, tpr)\n",
        "\n",
        "        roc_auc = np.array(roc_auc)\n",
        "        np.save(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + roc_auc_list[i] + tail, roc_auc)\n",
        "\n",
        "    cols = [[0], [1], [2], [3], [5], [0, 1, 2, 3, 5]]\n",
        "\n",
        "    fpr_list = [\"fpr_aleatoric\", \"fpr_epistemic\", \"fpr_scibilic\", \"fpr_entropy\", \"fpr_distance\", \"fpr_All\"]\n",
        "\n",
        "    tpr_list = [\"tpr_aleatoric\", \"tpr_epistemic\", \"tpr_scibilic\", \"tpr_entropy\", \"fpr_distance\", \"tpr_All\"]\n",
        "\n",
        "    roc_auc_list = [\"roc_auc_aleatoric\", \"roc_auc_epistemic\", \"roc_auc_scibilic\", \"roc_auc_entropy\", \"roc_auc_distance\", \"roc_auc_All\"]\n",
        "\n",
        "    legend_label = ['Aleatoric', 'Epistemic', 'Scibilic', 'Entropy', 'Distance', 'All']\n",
        "\n",
        "    for i,c in enumerate(cols):\n",
        "        lw = 2\n",
        "        fpr = np.load(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + fpr_list[i] + tail)\n",
        "        tpr = np.load(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + tpr_list[i] + tail)\n",
        "        roc_auc = np.load(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + roc_auc_list[i] + tail)[0]\n",
        "\n",
        "        plt.plot(fpr, tpr,lw=lw, label='%s (area = %0.2f)' % (legend_label[i], roc_auc))\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('FPR', fontsize=14)\n",
        "        plt.ylabel('TPR', fontsize=14)\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.title(f'Under {attack_type} attack with epsilon = {str(eps)}')\n",
        "    plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chose data attack type: \n",
            "Deepfool (1)\n",
            "FGSM  (2)\n",
            "BIM  (3)\n",
            "CW  (4)\n",
            "PGD  (5)\n",
            "\n",
            "3\n",
            "Enter epsilon value : \n",
            "\n",
            "0.04\n",
            "Chosen attack type is  BIM\n",
            "Chosen epsilon is  0.04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}